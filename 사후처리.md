### 현재 프로젝트는 '문서 전체 임베딩' 상태

-> 그러나! text-embedding-3-large 모델!
-> **'N차원의 피처(Feature)'**를 생성
-> "모델이 내부적으로 텍스트를 아주 작은 단위(토큰)로 쪼개고, 그 흐름을 파악해서 하나의 압축된 의미 보따리(벡터)로 만들었다"
-> 우리가 긴 문장을 읽을 때 "우대 / 금리 / 조건"처럼 의미 단위로 끊어 읽는 것과 비슷함.

### 결론은- 알잘딱깔센 openai라는 뜻-

구현 가능성을 체크하기 위한 '셀프 질문'
데이터가 있는가?: AI가 학습할 '입력(Feature)'과 '정답(Label)'이 쌍으로 묶인 데이터인가?

어떤 유형의 문제인가?: 숫자를 맞히는 것인가요(회귀), 종류를 나누는 것인가요(분류), 아니면 새로운 문장을 만드는 것인가요(생성)?

리소스가 충분한가?: 아주 무거운 모델(LLM)을 쓸 것인가요, 아니면 가벼운 모델을 경량화(Quantization)해서 쓸 것인가요?
