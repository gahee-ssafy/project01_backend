### 현재 프로젝트는 '문서 전체 임베딩' 상태 
text-embedding-3-large 모델! <br>
N차원의 피처(Feature)'를 생성: 숫자 주루룩..  <br>

### 그러나, 현안은 "1. n벡터에서 청킹 단위", "2. 해당사항 없으나 수만 개의 벡터로 뱉음"
  ### 1. 줄바꿈(\n)으로 나눔 chunks = spcl_cnd.split('\n')
  ### 2. 데이터 전처리(Preprocessing) 단계에서 비어 있는 값을 걸러내는 과정이 반드시 필요
  
  1. 보통 가장 유사한 조각들을 먼저 찾은 뒤, 이를 조합하는 방식으로 청킹 <br>
    [예시]
    "1.SC제일은행 최초 거래 신규고객에 대하여 우대 이율을 제공함 (보너스이율0.2%)
    2.SC제일마이백통장에서 출금하여 이 예금을 신규하는경우에 보너스이율을 제공함
    (가입기간:1년제/ 보너스이율:0.1% / 만기해약하는 경우에 한해 보너스이율을 적용함)" <br>
    단순 띄어쓰기는 너무 잘게 쪼게짐.

  2. "해당사항 없음"이나 수만 개의 벡터로 뱉음 : Garbage In, Garbage Out <br>
 

#################################

구현 가능성을 체크하기 위한 '셀프 질문'
데이터가 있는가?: AI가 학습할 '입력(Feature)'과 '정답(Label)'이 쌍으로 묶인 데이터인가?

어떤 유형의 문제인가?: 숫자를 맞히는 것인가요(회귀), 종류를 나누는 것인가요(분류), 아니면 새로운 문장을 만드는 것인가요(생성)?

리소스가 충분한가?: 아주 무거운 모델(LLM)을 쓸 것인가요, 아니면 가벼운 모델을 경량화(Quantization)해서 쓸 것인가요?
text-embedding-3-large 모델은 LLM.
경량도 써보고 싶다.. 
